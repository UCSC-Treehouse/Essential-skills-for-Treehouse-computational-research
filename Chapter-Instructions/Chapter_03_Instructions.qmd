---
title: "Chapter 3, Data Transformation"
format:
  gfm:
    self-contained: true
---

Visualization is an important tool for generating insight, but it’s rare that you get the data in exactly the right form you need to make the graph you want.
Often you’ll need to create some new variables or summaries to answer your questions with your data, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with.
You’ll learn how to do all that (and more!) in this chapter, which will introduce you to data transformation using the **dplyr** package and a new dataset on flights that departed from New York City in 2013.

The goal of this chapter is to give you an overview of all the key tools for transforming a data frame.

------------------------------------------------------------------------

## Prerequisites

In this chapter, we’ll focus on the dplyr package, another core member of the tidyverse.
We’ll illustrate the key ideas using data from the nycflights13 package and use ggplot2 to help us understand the data.

First, install necessary packages to access datasets and plotting functions --> copy the commands into your own **R Console**
```{r R CONSOLE prerequisites}
# install core packages (run once)
renv::install(c("nycflights13", "tidyverse"))
```

Load libraries from installed packages (*run every session*) --> copy the commands into your own **quarto notebook (.qmd file)**
```{r load libraries}
library(nycflights13)
library(tidyverse)
```

Take careful note of the conflicts message that’s printed when you load the tidyverse.
It tells you that dplyr overwrites some functions in base R.
If you want to use the base version of these functions after loading dplyr, you’ll need to use their full names: stats::filter() and stats::lag().

------------------------------------------------------------------------

## nycflights13

To explore the basic dplyr verbs, we will use nycflights13::flights.
This dataset contains all 336,776 flights that departed from New York City in 2013.
The data comes from the US [Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr) and is documented in ?flights.
```{r nycflights13 flights}
#| eval: false
flights
```

To inspect objects through different display options, try print(flights, width = Inf) to show all columns, or use glimpse():
```{r viewing flights}
#| eval: false
glimpse(flights)
```

In both views, the variable names are followed by abbreviations that tell you the type of each variable: <int> is short for integer, <dbl> is short for double (aka real numbers), <chr> for character (aka strings), and <dttm> for date-time.
These are important because the operations you can perform on a column depend heavily on its “**type**”.

------------------------------------------------------------------------

## dplyr Basics

Some background on the primary dplyr verbs (functions):

1. The first argument is always a data frame.
2. The subsequent arguments typically describe which columns to operate on using the variable names (without quotes).
3. The output is always a new data frame.

You can combine multiple verbs with a pipe |> which we can easily pronounce as "then". Try to read the following:
```{r pipe}
#| eval: false
flights |>
  filter(dest == "IAH") |> 
  group_by(year, month, day) |> 
  summarize(
    arr_delay = mean(arr_delay, na.rm = TRUE)
  )
```

dplyr’s verbs are organized into four groups based on what they operate on: **rows**, **columns**, **groups**, or **tables**.

------------------------------------------------------------------------

## Rows

The most important verbs that operate on rows of a dataset are filter(), which changes which rows are present without changing their order, and arrange(), which changes the order of the rows without changing which are present.
Both functions only affect the rows, and the columns are left unchanged.
We’ll also discuss distinct() which finds rows with unique values.
Unlike arrange() and filter() it can also optionally modify the columns.

filter() allows you to keep rows based on the values of the columns1.
The first argument is the data frame.
The second and subsequent arguments are the conditions that must be true to keep the row.
For example, we could find all flights that departed more than 120 minutes (two hours) late:
```{r filter}
#| eval: false
flights |> 
  filter(dep_delay > 120)
```

As well as > (greater than), you can use >= (greater than or equal to), < (less than), <= (less than or equal to), == (equal to), and != (not equal to).
You can also combine conditions with & or , to indicate “and” (check for both conditions) or with | to indicate “or” (check for either condition):
```{r multiple filter 1of2}
#| eval: false
# Flights that departed on January 1
flights |> 
  filter(month == 1 & day == 1)
```

```{r multiple filter 2of2}
#| eval: false
# Flights that departed in January or February
flights |> 
  filter(month == 1 | month == 2)
```

There’s a useful shortcut when you’re combining | and ==: %in%.
It keeps rows where the variable equals one of the values on the right:
```{r %in%}
#| eval: false
# A shorter way to select flights that departed in January or February
flights |> 
  filter(month %in% c(1, 2))
```

When you run filter() dplyr executes the filtering operation, creating a new data frame, and then prints it.
It doesn’t modify the existing flights dataset because dplyr functions never modify their inputs.
To save the result, you need to use the assignment operator, <-
```{r save results in variable}
#| eval: false
jan1 <- flights |> 
  filter(month == 1 & day == 1)
```

arrange() changes the order of the rows based on the value of the columns.
It takes a data frame and a set of column names (or more complicated expressions) to order by.
If you provide more than one column name, each additional column will be used to break ties in the values of the preceding columns.
For example, the following code sorts by the departure time, which is spread over four columns.
We get the earliest years first, then within a year, the earliest months, etc.
```{r arrange}
#| eval: false
flights |> 
  arrange(year, month, day, dep_time)
```

You can use desc() on a column inside of arrange() to re-order the data frame based on that column in descending (big-to-small) order.
For example, this code orders flights from most to least delayed:
```{r desc arrange}
#| eval: false
flights |> 
  arrange(desc(dep_delay))
```

distinct() finds all the unique rows in a dataset, so technically, it primarily operates on the rows.'
Most of the time, however, you’ll want the distinct combination of some variables, so you can also optionally supply column names:
```{r distinct}
#| eval: false
# Remove duplicate rows, if any
flights |> 
  distinct()
```

If you want to find the number of occurrences, you’re better off swapping distinct() for count().
With the sort = TRUE argument, you can arrange them in descending order of the number of occurrences.
You’ll learn more about count in Chapter 13.
```{r count}
#| eval: false
flights |>
  count(origin, dest, sort = TRUE)
```

------------------------------------------------------------------------

## Exercises pt 1 of 3

1. In a single pipeline for each condition, find all flights that meet the condition:
  -Had an arrival delay of two or more hours
  -Flew to Houston (IAH or HOU)
  -Were operated by United, American, or Delta
  -Departed in summer (July, August, and September)
  -Arrived more than two hours late but didn’t leave late
  -Were delayed by at least an hour, but made up over 30 minutes in flight

2. Sort flights to find the flights with the longest departure delays.
Find the flights that left earliest in the morning.

3. Sort flights to find the fastest flights.
(Hint: Try including a math calculation inside of your function.)

4. Was there a flight on every day of 2013?

5. Which flights traveled the farthest distance?
Which traveled the least distance?

6. Does it matter what order you used filter() and arrange() if you’re using both?
Why/why not?
Think about the results and how much work the functions would have to do.

------------------------------------------------------------------------

## Columns

There are four important verbs that affect the columns without changing the rows: mutate() creates new columns that are derived from the existing columns, select() changes which columns are present, rename() changes the names of the columns, and relocate() changes the positions of the columns.

The job of mutate() is to add new columns that are calculated from the existing columns.
In the transform chapters, you’ll learn a large set of functions that you can use to manipulate different types of variables.
For now, we’ll stick with basic algebra, which allows us to compute the gain, how much time a delayed flight made up in the air, and the speed in miles per hour:
```{r mutate}
#| eval: false
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60
  )
```

By default, mutate() adds new columns on the right-hand side of your dataset, which makes it difficult to see what’s happening here.
We can use the .before argument to instead add the variables to the left-hand side:
```{r left sided variables}
#| eval: false
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .before = 1
  )
```

The . indicates that .before is an argument to the function, not the name of a third new variable we are creating.
You can also use .after to add after a variable, and in both .before and .after you can use the variable name instead of a position.
For example, we could add the new variables after day:
```{r before and after}
#| eval: false
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .after = day
  )
```

Alternatively, you can control which variables are kept with the .keep argument.
A particularly useful argument is "used" which specifies that we only keep the columns that were involved or created in the mutate() step.
For example, the following output will contain only the variables dep_delay, arr_delay, air_time, gain, hours, and gain_per_hour.
```{r keep}
#| eval: false
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    hours = air_time / 60,
    gain_per_hour = gain / hours,
    .keep = "used"
  )
```

Note that since we haven’t assigned the result of the above computation back to flights, the new variables gain, hours, and gain_per_hour will only be printed but will not be stored in a data frame.
And if we want them to be available in a data frame for future use, we should think carefully about whether we want the result to be assigned back to flights, overwriting the original data frame with many more variables, or to a new object.
Often, the right answer is a new object that is named informatively to indicate its contents, e.g., delay_gain, but you might also have good reasons for overwriting flights.

select() allows you to rapidly zoom in on a useful subset using operations based on the names of the variables:

-Select columns by name:
```{r select by name}
#| eval: false
flights |> 
  select(year, month, day)
```

-Select all columns between x and z (eg year and day)
```{r select between}
#| eval: false
flights |> 
  select(year:day)
```

-Select all columns except those from x to z (eg year to day):
```{r select except}
#| eval: false
flights |> 
  select(!year:day)
```

-Select all columns that are characters:
```{r select chr}
#| eval: false
flights |> 
  select(where(is.character))
```

There are a number of helper functions you can use within select():

-starts_with("abc"): matches names that begin with “abc”.
-ends_with("xyz"): matches names that end with “xyz”.
-contains("ijk"): matches names that contain “ijk”.
-num_range("x", 1:3): matches x1, x2 and x3.

You can rename variables as you select() them by using =
```{r select equals}
#| eval: false
flights |> 
  select(tail_num = tailnum)
```

If you want to keep all the existing variables and just want to rename a few, you can use rename() instead of select():
```{r rename}
#| eval: false
flights |> 
  rename(tail_num = tailnum)
```

Use relocate() to move variables around.
```{r relocate}
#| eval: false
flights |> 
  relocate(time_hour, air_time)
```

You can also specify where to put them using the .before and .after arguments, just like in mutate():
```{r before and after in relocate}
#| eval: false
flights |> 
  relocate(year:dep_time, .after = time_hour)
flights |> 
  relocate(starts_with("arr"), .before = dep_time)
```

------------------------------------------------------------------------

## Exercises pt 2 of 3

1. Compare dep_time, sched_dep_time, and dep_delay.
How would you expect those three numbers to be related?

2. Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.

3. What happens if you specify the name of the same variable multiple times in a select() call?

4. What does the any_of() function do?
Why might it be helpful in conjunction with this vector?
```{r ch 3 exercise pt 2 #4}
#| eval: false
variables <- c("year", "month", "day", "dep_delay", "arr_delay")
```

5. Does the result of running the following code surprise you?
How do the select helpers deal with upper and lower case by default?
How can you change that default?
```{r ch 3 exercise pt 2 #5}
#| eval: false
flights |> select(contains("TIME"))
```

6. Rename air_time to air_time_min to indicate units of measurement and move it to the beginning of the data frame.

7. Why doesn’t the following work, and what does the error mean?
```{r ch 3 exercise pt 2 #7}
#| eval: false
flights |> 
  select(tailnum) |> 
  arrange(arr_delay)
```

------------------------------------------------------------------------

## The Pipe

Imagine that you wanted to find the fastest flights to Houston’s IAH airport: you need to combine filter(), mutate(), select(), and arrange():
```{r combine verbs}
#| eval: false
flights |> 
  filter(dest == "IAH") |> 
  mutate(speed = distance / air_time * 60) |> 
  select(year:day, dep_time, carrier, flight, speed) |> 
  arrange(desc(speed))
```

Use group_by() to divide your dataset into groups meaningful for your analysis:
```{r group by}
#| eval: false
flights |> 
  group_by(month)
```

The most important grouped operation is a **summary**, which, if being used to calculate a single summary statistic, reduces the data frame to have a single row for each group.
In dplyr, this operation is performed by summarize(), as shown by the following example, which computes the average departure delay by month:
```{r summarize}
#| eval: false
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay)
  )
```

Uh-oh! Something has gone wrong, and all of our results are **NAs**, R’s symbol for missing value.
This happened because some of the observed flights had missing data in the delay column, and so when we calculated the mean including those values, we got an NA result.
We’ll come back to discuss missing values in detail in Chapter 18, but for now, we’ll tell the mean() function to ignore all missing values by setting the argument na.rm to TRUE:
```{r ignore na}
#| eval: false
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE)
  )
```

One very useful summary is n(), which returns the number of rows in each group:
```{r number of rows}
#| eval: false
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE), 
    n = n()
  )
```

There are five handy functions that allow you to extract specific rows within each group:

-df |> slice_head(n = 1) takes the first row from each group.
-df |> slice_tail(n = 1) takes the last row in each group.
-df |> slice_min(x, n = 1) takes the row with the smallest value of column x.
-df |> slice_max(x, n = 1) takes the row with the largest value of column x.
-df |> slice_sample(n = 1) takes one random row.

You can create groups using more than one variable.
For example, we could make a group for each date.
```{r group by variable}
#| eval: false
daily <- flights |>  
  group_by(year, month, day)
daily
```

You might also want to remove grouping from a data frame without using summarize().
You can do this with ungroup().
```{r ungroup}
#| eval: false
daily |> 
  ungroup()
```

dplyr 1.1.0 includes a new, experimental, syntax for per-operation grouping, the .by argument.
You can now also use the .by argument to group within a single operation:
```{r by}
#| eval: false
flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = month
  )
```

Group by multiple variables:
```{r group by multi variables}
#| eval: false
flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = c(origin, dest)
  )
```

.by works with all verbs!

------------------------------------------------------------------------

## Exercises pt 3 of 3

1. Which carrier has the worst average delays?
Challenge: can you disentangle the effects of bad airports vs. bad carriers?
Why/why not?
(Hint: think about flights |> group_by(carrier, dest) |> summarize(n()))

2. Find the flights that are most delayed upon departure from each destination.

3. How do delays vary over the course of the day?
Illustrate your answer with a plot.

4. What happens if you supply a negative n to slice_min() and friends?

5. Explain what count() does in terms of the dplyr verbs you just learned.
What does the sort argument to count() do?

6. Suppose we have the following tiny data frame:
```{r ch 3 exercise pt 3 #6}
#| eval: false
df <- tibble(
  x = 1:5,
  y = c("a", "b", "a", "a", "b"),
  z = c("K", "K", "L", "L", "K")
)
```

6a. Write down what you think the output will look like, then check if you were correct, and describe what group_by() does.
```{r ch 3 exercise pt 3 #6a}
#| eval: false
df |>
  group_by(y)
```

6b. Write down what you think the output will look like, then check if you were correct, and describe what arrange() does.
Also, comment on how it’s different from the group_by() in part (a).
```{r ch 3 exercise pt 3 #6b}
#| eval: false
df |>
  arrange(y)
```

6c. Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.
```{r ch 3 exercise pt 3 #6c}
#| eval: false
df |>
  group_by(y) |>
  summarize(mean_x = mean(x))
```

6d. Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.
Then, comment on what the message says.
```{r ch 3 exercise pt 3 #6d}
#| eval: false
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))
```

6e. Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.
How is the output different from the one in part (d)?
```{r ch 3 exercise pt 3 #6e}
#| eval: false
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x), .groups = "drop")
```

6f. Write down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does.
How are the outputs of the two pipelines different?
```{r ch 3 exercise pt 3 #6f}
#| eval: false
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

df |>
  group_by(y, z) |>
  mutate(mean_x = mean(x))
```

------------------------------------------------------------------------

## Case Study: Aggregates and Sample Size

Whenever you do any aggregation, it’s always a good idea to include a count (n()).

We will use the **Lahman** package.
Specifically, we will compare what proportion of times a player gets a hit (H) vs. the number of times they try to put the ball in play (AB):
```{r count summarize}
#| eval: false
# load library Lahman
library(Lahman)

batters <- Lahman::Batting |> 
  group_by(playerID) |> 
  summarize(
    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    n = sum(AB, na.rm = TRUE)
  )
batters
```

Let's plot the skill of the batter (measured by the batting average, performance) against the number of opportunities to hit the ball (measured by times at bat, n)
```{r skill of batter}
#| eval: false
batters |> 
  filter(n > 100) |> 
  ggplot(aes(x = n, y = performance)) +
  geom_point(alpha = 1 / 10) + 
  geom_smooth(se = FALSE)
```